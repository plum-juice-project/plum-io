[{"data":1,"prerenderedAt":1314},["ShallowReactive",2],{"blog":3},[4,120,355,996],{"_path":5,"_dir":6,"_draft":7,"_partial":7,"_locale":8,"title":9,"description":10,"author":11,"gh_nickname":12,"image":13,"date":14,"body":15,"_type":114,"_id":115,"_source":116,"_file":117,"_stem":118,"_extension":119},"/blog/a_journey_at_sc24","blog",false,"","A Journey at SC24","This article is a firsthand account of my journey as a student volunteer at the Supercomputing Conference 2024 (SC24), the largest event dedicated to high-performance computing (HPC). It explores the technical innovations, inspiring keynotes, and collaborative spirit that make SC a unique experience. Through personal anecdotes, I share how the conference helped me organize my thoughts, connect with like-minded peers, and discover my path in the vast world of HPC. From the awe of seeing groundbreaking technologies to the importance of building a supportive community.","Lorenzo Piarulli","lor3ny","https://media.licdn.com/dms/image/v2/D4D22AQG8XthITyx-9A/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1733404270188?e=1736380800&v=beta&t=CdUYx0NBso8HVul7hHwNqaTe0HPPhcUdOw5g88Kj-iw","2024-12-09",{"type":16,"children":17,"toc":107},"root",[18,26,31,48,55,60,67,72,77,91,97,102],{"type":19,"tag":20,"props":21,"children":22},"element","p",{},[23],{"type":24,"value":25},"text","This year, our juice was taken to one of the most important conferences in the world in the remote and exotic Atlanta, in the USA. Despite the temptation to invest all of our limited savings in cutting-edge technologies such as immersion cooling systems, 8-GPU racks, enormous hamburgers, or state-of-the-art accelerators, we resisted. Navigating through numerous temptations, we are truly thrilled to have been part of such a pioneering and outstanding community.",{"type":19,"tag":20,"props":27,"children":28},{},[29],{"type":24,"value":30},"Hi everyone, I'm Lorenzo. This year, I had the privilege of volunteering as a student at the Supercomputing conference '24 (SC24). SC24 is renowned as the largest gathering focused on high-performance computing (HPC), attracting researchers from those working on the cutting edge of supercomputing hardware to scientists utilizing HPC systems for their scientific applications. The conference features a diverse array of events, including technical paper presentations, workshops, panels, tutorials, Birds of a Feather (BoF) sessions, and keynotes. Each type of event has its own unique format, ranging from formal paper presentations to open discussions with recognized experts in the field. The technical events, such as paper presentations, workshops, and Birds of a Feather (BoFs), play a crucial role in showcasing the year's groundbreaking discoveries that are shaping the future of how supercomputers are designed and utilized. They serve as the foundation of the research community and the backbone of the conference, driving innovation and collaboration in the field.\nPanels are probably some of the most exciting events at the conference. They‚Äôre open discussions on big, important topics that can range from deep technical insights to inclusivity and work-life balance. It‚Äôs awesome to join these sessions and watch research legends share their knowledge, breaking things down to help you better understand what‚Äôs happening in this massive field. They‚Äôre also there to guide you and maybe even help you find your own path forward\nThe tempting ring is hidden on the exhibit floor, a vibrant hub where companies, national laboratories, academic institutions, and open-source foundations showcase their stands. Here, attendees can explore the latest, most powerful, and most advanced technologies. This includes groundbreaking, powerful architectures, new enormous and noisy cooling systems that could cool down Vhagar, big racks that can fuse multiple bizarre accelerators, and more juicy stuff. The exhibit opening is a great chance to meet people, make new connections, learn about cool research, and even find opportunities for future collaborations.",{"type":19,"tag":32,"props":33,"children":34},"figure",{},[35,37,41,42],{"type":24,"value":36},"\n    ",{"type":19,"tag":38,"props":39,"children":40},"img",{"src":13,"alt":8},[],{"type":24,"value":36},{"type":19,"tag":43,"props":44,"children":45},"figcaption",{},[46],{"type":24,"value":47},"First plenaria of the conference.",{"type":19,"tag":49,"props":50,"children":52},"h3",{"id":51},"the-keynote",[53],{"type":24,"value":54},"The Keynote:",{"type":19,"tag":20,"props":56,"children":57},{},[58],{"type":24,"value":59},"One of the highlights of every SC conference is the keynote. It‚Äôs a speech delivered on the main stage by a distinguished researcher. This year, we had the privilege of hearing from Nicola Fox, NASA‚Äôs associate administrator, who talked about how supercomputers are revolutionizing the way NASA conducts its missions and simulations, making them more accurate and effective.\nHer talk was incredible‚Äîit started with the Voyager Space Probe, which has now ventured into interstellar space. From there, she covered the discovery of new exoplanets, and the search for simple life on Europa, one of Jupiter‚Äôs moons, and wrapped up with the significance of simulating supernovae, dying stars, and black holes.\nIt was, without a doubt, one of the most impactful speeches I‚Äôve ever heard. It inspired me to pursue a research career in this field, focusing on accelerating scientific applications to enable groundbreaking discoveries, improve people‚Äôs lives, and help build a better future.",{"type":19,"tag":61,"props":62,"children":64},"h2",{"id":63},"sc24-is-not-only-nerdy-stuff-its-also-community",[65],{"type":24,"value":66},"SC24 is not only nerdy stuff, It's also community",{"type":19,"tag":20,"props":68,"children":69},{},[70],{"type":24,"value":71},"This event has been a milestone in my student journey, giving me a deeper understanding of the HPC world and the chance to meet and talk with the brilliant minds who build and use these incredible systems. As a student volunteer, one of the coolest perks is being able to wander around freely and soak in all the amazing things happening at the conference.\nIt‚Äôs like stepping into the multiverse of HPC. One moment, you‚Äôre diving into colossal simulations of supernovae, black holes, and planets that seem to breathe with life. The next, you‚Äôre in microcosmic realms of particles, molecules, proteins, and the very essence of life itself. It‚Äôs mind-blowing to see how HPC reshapes our understanding of the universe or how it revolutionizes life on Earth, enabling the creation of groundbreaking medicines to tackle the most enigmatic and devastating diseases. It‚Äôs science fiction come to life, powered by computation.",{"type":19,"tag":20,"props":73,"children":74},{},[75],{"type":24,"value":76},"During the conference, you get to collaborate with your fellow student volunteers, and for me, this collaboration was invaluable. It helped me forge new friendships with people who share my values, vision, and passions. One of the best parts is hanging out with students from all over the world, geeking out about your thesis or nerdy projects, and realizing they either totally relate to your excitement or are genuinely eager to hear every word of it.\nI met some truly amazing people who are unapologetically passionate about what they do. This community feels like a safe haven, especially for those who might struggle to fit into a world that sometimes sees computer geeks as outsiders. Here, everyone is valued for who they are. It‚Äôs a place where you can share your ideas, your struggles, or even your latest D&D campaign without fear of judgment. It‚Äôs like finding your own fellowship of the ring‚Äîexcept this one runs on algorithms, GPUs, and an endless supply of curiosity.",{"type":19,"tag":32,"props":78,"children":79},{},[80,81,85,86],{"type":24,"value":36},{"type":19,"tag":38,"props":82,"children":84},{"src":83,"alt":8},"https://media.licdn.com/dms/image/v2/D4D22AQG6l08wlSiQ7w/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1733404277053?e=1736380800&v=beta&t=b5A2LSf-9MMTi3MVCP2nh3c8c7imGeroHz4sBDjNc80",[],{"type":24,"value":36},{"type":19,"tag":43,"props":87,"children":88},{},[89],{"type":24,"value":90},"All the students volunteers.",{"type":19,"tag":61,"props":92,"children":94},{"id":93},"yes-i-loved-it",[95],{"type":24,"value":96},"Yes, I loved it",{"type":19,"tag":20,"props":98,"children":99},{},[100],{"type":24,"value":101},"I've arrive at SC24 as a student with a million unordered thoughts swirling in my head. But through conversations with students like me, I managed to organize those ideas and start finding my place in the vast world of HPC. It gave me a clear vision of the many paths HPC offers‚Äîand helped me figure out which ones I want to explore and improve.\nLooking back, SC24 taught me countless things, but two stand out that I‚Äôll carry with me forever. First, PlumJuice began as a labor of love‚Äîa way to share our secret nerdy passions for fast, interconnected, and ‚Äútasty‚Äù ideas. SC24 showed me just how important it is to build a community that understands and embraces your feelings, passions, and even fears.\nSecond, SC24 reminded me of the profound importance of research in our field. It takes people willing to dedicate part of their lives to chasing what often feels like fantasies and magic. But those fantasies can lead to groundbreaking discoveries that change lives and reshape how we relate to the world. HPC can be the bridge between imagination and reality‚Äîa tool to turn dreams into revolutions.\nI‚Äôm thrilled to join this incredible community and dedicate my efforts to the HPC field. I don‚Äôt care about where it takes me or the recognition I might get. All I want is to work on something meaningful and make a difference for others. After all, in the words of a wise wizard, ‚ÄúAll we have to decide is what to do with the time that is given us.‚Äù And I‚Äôve made my choice.",{"type":19,"tag":103,"props":104,"children":106},"credits",{":authors":105},"[{\"name\":\"Lorenzo Piarulli\",\"github_nickname\":\"lor3ny\"}]",[],{"title":8,"searchDepth":108,"depth":108,"links":109},2,[110,112,113],{"id":51,"depth":111,"text":54},3,{"id":63,"depth":108,"text":66},{"id":93,"depth":108,"text":96},"markdown","content:blog:a_journey_at_sc24.md","content","blog/a_journey_at_sc24.md","blog/a_journey_at_sc24","md",{"_path":121,"_dir":6,"_draft":7,"_partial":7,"_locale":8,"title":122,"description":123,"author":124,"gh_nickname":125,"image":126,"date":127,"body":128,"_type":114,"_id":352,"_source":116,"_file":353,"_stem":354,"_extension":119},"/blog/weekly_update_29-11","Weekly Update 29-11","29-11 weekly update from the PlumJuice team","Simone Palmieri","sudo-err","https://res.cloudinary.com/dllutk9zl/image/upload/v1732897195/presentation_cut_lhrepv.jpg","2024-11-29",{"type":16,"children":129,"toc":345},[130,136,141,154,173,199,212,218,242,256,262,274,288,294,313,319,331,341],{"type":19,"tag":61,"props":131,"children":133},{"id":132},"we-presented-the-cluster-to-students",[134],{"type":24,"value":135},"We presented the cluster to students!",{"type":19,"tag":20,"props":137,"children":138},{},[139],{"type":24,"value":140},"This week was mainly focused on the class presentation we did on wednesday, so this one will be a lighter update with less HPC news and more... juice (I don't even know).",{"type":19,"tag":20,"props":142,"children":143},{},[144,146,152],{"type":24,"value":145},"First of all, our biggest thank you goes to professor ",{"type":19,"tag":147,"props":148,"children":149},"strong",{},[150],{"type":24,"value":151},"Daniele De Sensi",{"type":24,"value":153}," that allowed us to talk at his lecture on Multicore Programming.",{"type":19,"tag":20,"props":155,"children":156},{},[157,159,164,166,171],{"type":24,"value":158},"We were able to talk about the genesis, current state and future developments of the project, and a huge thanks goes to the ",{"type":19,"tag":147,"props":160,"children":161},{},[162],{"type":24,"value":163},"students",{"type":24,"value":165}," that were really passionate about the plum! Or maybe they just wanted ",{"type":19,"tag":147,"props":167,"children":168},{},[169],{"type":24,"value":170},"stickers",{"type":24,"value":172},". But I get it, they're amazing.",{"type":19,"tag":20,"props":174,"children":175},{},[176,178,189,191,197],{"type":24,"value":177},"Another lucky event took place at the presentation, but you'll have to check ",{"type":19,"tag":179,"props":180,"children":186},"a",{"href":181,"rel":182,"target":185},"https://instagram.com/plumjuiceteam",[183,184],"noopener","noreferer","_blank",[187],{"type":24,"value":188},"our Instagram",{"type":24,"value":190}," for that (that's what we call a ",{"type":19,"tag":192,"props":193,"children":194},"em",{},[195],{"type":24,"value":196},"\"call to action\"",{"type":24,"value":198},", you nerds).",{"type":19,"tag":32,"props":200,"children":201},{},[202,203,206,207],{"type":24,"value":36},{"type":19,"tag":38,"props":204,"children":205},{"src":126,"alt":8},[],{"type":24,"value":36},{"type":19,"tag":43,"props":208,"children":209},{},[210],{"type":24,"value":211},"Presentation in classroom on November 27th",{"type":19,"tag":61,"props":213,"children":215},{"id":214},"were-on-patreon",[216],{"type":24,"value":217},"We're on Patreon!",{"type":19,"tag":20,"props":219,"children":220},{},[221,223,228,230,240],{"type":24,"value":222},"Yes you read that right (hopefully)! You can now support us on the ",{"type":19,"tag":192,"props":224,"children":225},{},[226],{"type":24,"value":227},"second",{"type":24,"value":229}," most famous platform to give money to perfect strangers! Just go ",{"type":19,"tag":147,"props":231,"children":232},{},[233],{"type":19,"tag":179,"props":234,"children":237},{"href":235,"rel":236,"target":185},"https://www.patreon.com/PlumJuiceTeam",[183,184],[238],{"type":24,"value":239},"HERE",{"type":24,"value":241}," and chek out the juicy rewards we made for our top supporters, you won't regret it.",{"type":19,"tag":32,"props":243,"children":244},{},[245,246,250,251],{"type":24,"value":36},{"type":19,"tag":38,"props":247,"children":249},{"src":248,"alt":8},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732897197/patreon_yvnrh5.jpg",[],{"type":24,"value":36},{"type":19,"tag":43,"props":252,"children":253},{},[254],{"type":24,"value":255},"Go check it out!",{"type":19,"tag":61,"props":257,"children":259},{"id":258},"our-amazing-woodwork",[260],{"type":24,"value":261},"Our amazing woodwork",{"type":19,"tag":20,"props":263,"children":264},{},[265,267,272],{"type":24,"value":266},"You've already seen it empty in the previous weekly update, but if you were at the live presentation you had a glance of the immense computational power we assembled. It would be cruel to keep this magnificent view to ourselves, so here it is: ",{"type":19,"tag":147,"props":268,"children":269},{},[270],{"type":24,"value":271},"the wooden rack",{"type":24,"value":273},".",{"type":19,"tag":32,"props":275,"children":276},{},[277,278,282,283],{"type":24,"value":36},{"type":19,"tag":38,"props":279,"children":281},{"src":280,"alt":8},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732897201/wood_rack_cut_df3rzh.jpg",[],{"type":24,"value":36},{"type":19,"tag":43,"props":284,"children":285},{},[286],{"type":24,"value":287},"Majestic.",{"type":19,"tag":61,"props":289,"children":291},{"id":290},"weve-got-99-problems-and-topology-is-one-but-not-for-long",[292],{"type":24,"value":293},"We've got 99 problems and topology is one (but not for long)",{"type":19,"tag":20,"props":295,"children":296},{},[297,299,304,306,311],{"type":24,"value":298},"If you're one of our beloved early plums you know that the ",{"type":19,"tag":147,"props":300,"children":301},{},[302],{"type":24,"value":303},"cluster's topology",{"type":24,"value":305}," is one of the main topics we spend time working on. At its current state it's not optimal, as some network congestion is possible due to the type of switches we use now and the DHCP state. It is not a problem for now, since the workload is light, but it may be in the near future. Luckily, a solution is in the air and it involves some ",{"type":19,"tag":192,"props":307,"children":308},{},[309],{"type":24,"value":310},"soldering",{"type":24,"value":312},", so if you happen to smell something burning don't worry it's us (or you're having a stroke).",{"type":19,"tag":61,"props":314,"children":316},{"id":315},"ernestos-challenge-of-the-week",[317],{"type":24,"value":318},"Ernesto's challenge of the week",{"type":19,"tag":20,"props":320,"children":321},{},[322,324,329],{"type":24,"value":323},"The world's best SysAdmin never rests, and this week he found another worthy opponent: ",{"type":19,"tag":147,"props":325,"children":326},{},[327],{"type":24,"value":328},"Docker swarm",{"type":24,"value":330},". Will he win? Will this new test get the better of him? Stay tuned to find out...",{"type":19,"tag":32,"props":332,"children":335},{"className":333},[334],"not-centerd",[336,337],{"type":24,"value":36},{"type":19,"tag":38,"props":338,"children":340},{"src":339,"alt":8},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732897511/jojo_kdui48.jpg",[],{"type":19,"tag":103,"props":342,"children":344},{":authors":343},"[{\"name\":\"Simone Palmieri\",\"github_nickname\":\"sudo-err\"}]",[],{"title":8,"searchDepth":108,"depth":108,"links":346},[347,348,349,350,351],{"id":132,"depth":108,"text":135},{"id":214,"depth":108,"text":217},{"id":258,"depth":108,"text":261},{"id":290,"depth":108,"text":293},{"id":315,"depth":108,"text":318},"content:blog:weekly_update_29-11.md","blog/weekly_update_29-11.md","blog/weekly_update_29-11",{"_path":356,"_dir":6,"_draft":7,"_partial":7,"_locale":8,"title":357,"description":358,"author":359,"gh_nickname":360,"date":361,"image":362,"body":363,"_type":114,"_id":993,"_source":116,"_file":994,"_stem":995,"_extension":119},"/blog/weekly_update_22-11","Weekly Update 22-11","The week began with the cluster almost in a ready state, but issues emerged during testing with MPI and SLURM. Specifically: SLURM (srun) Only ran in singleton mode without errors but failed to scale. MPI (mpirun) Crashed outright, returning an error: \"PSEC: munge failed to create credential: Socket communication error.\"","Alessio Olivieri","Alessio-Olivieri","2024-11-22T00:00:00.000Z","https://res.cloudinary.com/dllutk9zl/image/upload/v1732270953/Plum_at_SC24_eozc8d.jpg",{"type":16,"children":364,"toc":975},[365,371,376,417,444,450,462,467,483,488,526,532,551,570,576,585,590,597,603,608,614,620,625,631,668,674,679,685,690,723,729,734,740,928,934,953,958,971],{"type":19,"tag":61,"props":366,"children":368},{"id":367},"cluster-issues-with-mpi-and-slurm",[369],{"type":24,"value":370},"Cluster Issues with MPI and SLURM",{"type":19,"tag":20,"props":372,"children":373},{},[374],{"type":24,"value":375},"The week began with the cluster almost in a ready state, but issues emerged during testing with MPI and SLURM. Specifically:",{"type":19,"tag":377,"props":378,"children":379},"ul",{},[380,400],{"type":19,"tag":381,"props":382,"children":383},"li",{},[384,398],{"type":19,"tag":147,"props":385,"children":386},{},[387,389,396],{"type":24,"value":388},"SLURM (",{"type":19,"tag":390,"props":391,"children":393},"code",{"className":392},[],[394],{"type":24,"value":395},"srun",{"type":24,"value":397},")",{"type":24,"value":399},": Only ran in singleton mode without errors but failed to scale.",{"type":19,"tag":381,"props":401,"children":402},{},[403,415],{"type":19,"tag":147,"props":404,"children":405},{},[406,408,414],{"type":24,"value":407},"MPI (",{"type":19,"tag":390,"props":409,"children":411},{"className":410},[],[412],{"type":24,"value":413},"mpirun",{"type":24,"value":397},{"type":24,"value":416},": Crashed outright, returning an error: \"PSEC: munge failed to create credential: Socket communication error.\"",{"type":19,"tag":20,"props":418,"children":419},{},[420,422,427,429,435,437,442],{"type":24,"value":421},"The issue was ",{"type":19,"tag":147,"props":423,"children":424},{},[425],{"type":24,"value":426},"Munge",{"type":24,"value":428},", a tool SLURM uses for authentication across nodes. Although all nodes had it installed and shared the same ",{"type":19,"tag":390,"props":430,"children":432},{"className":431},[],[433],{"type":24,"value":434},"munge.key",{"type":24,"value":436},", ",{"type":19,"tag":390,"props":438,"children":440},{"className":439},[],[441],{"type":24,"value":413},{"type":24,"value":443}," continued to fail.",{"type":19,"tag":49,"props":445,"children":447},{"id":446},"solution-attempts-and-breakthrough",[448],{"type":24,"value":449},"Solution Attempts and Breakthrough",{"type":19,"tag":20,"props":451,"children":452},{},[453,455,460],{"type":24,"value":454},"After trying several fixes, we found a relevant article by ",{"type":19,"tag":147,"props":456,"children":457},{},[458],{"type":24,"value":459},"Hossein Ghorbanfekr",{"type":24,"value":461}," on Medium, which detailed a similar setup using Raspberry Pi 4 with a Pi 3 as master: he compiled SLURM, and MPI from scratch and his setup was working, however the same authentication issue persisted.",{"type":19,"tag":20,"props":463,"children":464},{},[465],{"type":24,"value":466},"Later, a deeper research persisted by Ernesto revealed an Intel cluster user‚Äôs solution:",{"type":19,"tag":377,"props":468,"children":469},{},[470],{"type":19,"tag":381,"props":471,"children":472},{},[473,475,481],{"type":24,"value":474},"By setting ",{"type":19,"tag":390,"props":476,"children":478},{"className":477},[],[479],{"type":24,"value":480},"PMIX_MCA_psec0=native",{"type":24,"value":482},", MPI bypassed Munge and used its default authentication. This change allowed MPI to communicate properly across nodes without the Munge authentication layer.",{"type":19,"tag":20,"props":484,"children":485},{},[486],{"type":24,"value":487},"Testing this:",{"type":19,"tag":377,"props":489,"children":490},{},[491,513],{"type":19,"tag":381,"props":492,"children":493},{},[494,503,505,511],{"type":19,"tag":147,"props":495,"children":496},{},[497],{"type":19,"tag":390,"props":498,"children":500},{"className":499},[],[501],{"type":24,"value":502},"PMIX_MCA_psec0=munge",{"type":24,"value":504}," with ",{"type":19,"tag":390,"props":506,"children":508},{"className":507},[],[509],{"type":24,"value":510},"srun -n 16 hostname",{"type":24,"value":512}," worked.",{"type":19,"tag":381,"props":514,"children":515},{},[516,524],{"type":19,"tag":147,"props":517,"children":518},{},[519],{"type":19,"tag":390,"props":520,"children":522},{"className":521},[],[523],{"type":24,"value":413},{"type":24,"value":525}," still faced issues, which we plan to address when we have more time, as the current priority is communication stability.",{"type":19,"tag":61,"props":527,"children":529},{"id":528},"hardware-upgrade",[530],{"type":24,"value":531},"Hardware Upgrade",{"type":19,"tag":20,"props":533,"children":534},{},[535,537,542,544,549],{"type":24,"value":536},"We decided to include the previous master ",{"type":19,"tag":147,"props":538,"children":539},{},[540],{"type":24,"value":541},"Ciz0",{"type":24,"value":543}," (The only node with 8GB of RAM) in the computational nodes and passed the role of the master to ",{"type":19,"tag":147,"props":545,"children":546},{},[547],{"type":24,"value":548},"Andrea",{"type":24,"value":550},", a Raspberry Pi 3b with 1 GB of RAM, enhancing the cluster specs:",{"type":19,"tag":377,"props":552,"children":553},{},[554,562],{"type":19,"tag":381,"props":555,"children":556},{},[557],{"type":19,"tag":147,"props":558,"children":559},{},[560],{"type":24,"value":561},"28GB -> 36 GB of RAM",{"type":19,"tag":381,"props":563,"children":564},{},[565],{"type":19,"tag":147,"props":566,"children":567},{},[568],{"type":24,"value":569},"28->32 cores",{"type":19,"tag":49,"props":571,"children":573},{"id":572},"potential-problems-of-this-approach",[574],{"type":24,"value":575},"Potential Problems of this approach",{"type":19,"tag":20,"props":577,"children":578},{},[579,583],{"type":19,"tag":147,"props":580,"children":581},{},[582],{"type":24,"value":541},{"type":24,"value":584}," still handles the filesystem... This might be a potential bottleneck when the multiple users try to use the server at the same time since it has more tasks to do.",{"type":19,"tag":20,"props":586,"children":587},{},[588],{"type":24,"value":589},"The problem will be solved when the filesystem will be handled by the master, which will happen when we get more raspberries",{"type":19,"tag":591,"props":592,"children":594},"h5",{"id":593},"saverio-is-now-satisfied-that-his-previously-underutilized-hardware-was-put-to-work",[595],{"type":24,"value":596},"Saverio is now satisfied that his previously underutilized hardware was put to work!",{"type":19,"tag":49,"props":598,"children":600},{"id":599},"next-steps",[601],{"type":24,"value":602},"Next Steps",{"type":19,"tag":20,"props":604,"children":605},{},[606],{"type":24,"value":607},"Using munge for the authentication will be scheduled for later, as we prioritize cluster stability for the presentation of the 13/11/24 (which has been rescheduled for the 20/11/24)",{"type":19,"tag":61,"props":609,"children":611},{"id":610},"plum-juice-cluster-presentation-in-the-multicore-class",[612],{"type":24,"value":613},"Plum juice cluster presentation in the multicore class",{"type":19,"tag":49,"props":615,"children":617},{"id":616},"make-the-world-know-about-us",[618],{"type":24,"value":619},"Make the world know about us.",{"type":19,"tag":20,"props":621,"children":622},{},[623],{"type":24,"value":624},"Professor De Sensi gave us 15 minutes of it's multicore classto present our cluster to the students. This is a big opportunity to expand the plum juice team and to make the world know about us!",{"type":19,"tag":49,"props":626,"children":628},{"id":627},"whats-the-multicore-course-about",[629],{"type":24,"value":630},"What's the multicore course about?",{"type":19,"tag":20,"props":632,"children":633},{},[634,636,641,642,647,649,654,656,661,662,667],{"type":24,"value":635},"The multicore course has been tought to give a deep understanding and practical experience about parallel programming. This is done by proposing the students homeworks where they have to implement classic parallelizable problems like ",{"type":19,"tag":192,"props":637,"children":638},{},[639],{"type":24,"value":640},"matrix multiplication",{"type":24,"value":436},{"type":19,"tag":192,"props":643,"children":644},{},[645],{"type":24,"value":646},"histograms computation",{"type":24,"value":648}," and ",{"type":19,"tag":192,"props":650,"children":651},{},[652],{"type":24,"value":653},"integral approximation",{"type":24,"value":655},". The taught libraries are: ",{"type":19,"tag":192,"props":657,"children":658},{},[659],{"type":24,"value":660},"MPI, OpenMP, Pthreads",{"type":24,"value":648},{"type":19,"tag":192,"props":663,"children":664},{},[665],{"type":24,"value":666},"Cuda",{"type":24,"value":273},{"type":19,"tag":49,"props":669,"children":671},{"id":670},"what-do-we-offer",[672],{"type":24,"value":673},"What do we offer?",{"type":19,"tag":20,"props":675,"children":676},{},[677],{"type":24,"value":678},"The Plum juice team offers to give students the possibility to easily test their applications on a truly multi node system, effectively simulating more expensive clusters like Leonardo.",{"type":19,"tag":49,"props":680,"children":682},{"id":681},"our-expectations",[683],{"type":24,"value":684},"Our expectations.",{"type":19,"tag":20,"props":686,"children":687},{},[688],{"type":24,"value":689},"Every plum has their own expectactions from this presentation:",{"type":19,"tag":377,"props":691,"children":692},{},[693,703,713],{"type":19,"tag":381,"props":694,"children":695},{},[696,701],{"type":19,"tag":147,"props":697,"children":698},{},[699],{"type":24,"value":700},"Ciz:",{"type":24,"value":702}," We're dumb",{"type":19,"tag":381,"props":704,"children":705},{},[706,711],{"type":19,"tag":147,"props":707,"children":708},{},[709],{"type":24,"value":710},"Saverio:",{"type":24,"value":712}," I expect money",{"type":19,"tag":381,"props":714,"children":715},{},[716,721],{"type":19,"tag":147,"props":717,"children":718},{},[719],{"type":24,"value":720},"Lachi:",{"type":24,"value":722}," ehhh booh... nobody will be interested",{"type":19,"tag":49,"props":724,"children":726},{"id":725},"where-and-when-can-you-find-us",[727],{"type":24,"value":728},"Where and when can you find us:",{"type":19,"tag":20,"props":730,"children":731},{},[732],{"type":24,"value":733},"Aula A1, Via del Castro Laurenziano at 14:00.",{"type":19,"tag":61,"props":735,"children":737},{"id":736},"behind-the-scenes-when-nothing-was-still-working",[738],{"type":24,"value":739},"Behind the scenes, when nothing was still working",{"type":19,"tag":741,"props":742,"children":743},"blockquote",{},[744,754,763,772,782,791,800,809,819,828,837,846,852,859,868,878,880,886,896,905,915,917],{"type":19,"tag":20,"props":745,"children":746},{},[747,752],{"type":19,"tag":147,"props":748,"children":749},{},[750],{"type":24,"value":751},"Ciz",{"type":24,"value":753},": Ok, now Slurm is starting!",{"type":19,"tag":20,"props":755,"children":756},{},[757,761],{"type":19,"tag":147,"props":758,"children":759},{},[760],{"type":24,"value":751},{"type":24,"value":762},": Oh no, just kidding... it can't find the node name. Perfect, we're off to a great start.",{"type":19,"tag":20,"props":764,"children":765},{},[766,770],{"type":19,"tag":147,"props":767,"children":768},{},[769],{"type":24,"value":751},{"type":24,"value":771},": Guys, the configuration file is full of errors... honestly, it's embarrassing.",{"type":19,"tag":20,"props":773,"children":774},{},[775,780],{"type":19,"tag":147,"props":776,"children":777},{},[778],{"type":24,"value":779},"Saverio",{"type":24,"value":781},": Umm... maybe because you're running it from the master? Just a thought.",{"type":19,"tag":20,"props":783,"children":784},{},[785,789],{"type":19,"tag":147,"props":786,"children":787},{},[788],{"type":24,"value":751},{"type":24,"value":790},": Why doesn't poor ciz0 have Slurm installed? This is discrimination!",{"type":19,"tag":20,"props":792,"children":793},{},[794,798],{"type":19,"tag":147,"props":795,"children":796},{},[797],{"type":24,"value":751},{"type":24,"value":799},": Fine, I just need to add it to the playbook, right?",{"type":19,"tag":20,"props":801,"children":802},{},[803,807],{"type":19,"tag":147,"props":804,"children":805},{},[806],{"type":24,"value":751},{"type":24,"value":808},": Wait, so it's not installed at all. Great.",{"type":19,"tag":20,"props":810,"children":811},{},[812,817],{"type":19,"tag":147,"props":813,"children":814},{},[815],{"type":24,"value":816},"Ernesto",{"type":24,"value":818},": Actually, if there's no Munge, Slurm won't even acknowledge you. It's like an honor code.",{"type":19,"tag":20,"props":820,"children":821},{},[822,826],{"type":19,"tag":147,"props":823,"children":824},{},[825],{"type":24,"value":751},{"type":24,"value":827},": Ok, summary: changed the master password, removed TaskAffinity from the config because it was throwing errors anyway. Don't ask me why it's in the docs, but it doesn't work.",{"type":19,"tag":20,"props":829,"children":830},{},[831,835],{"type":19,"tag":147,"props":832,"children":833},{},[834],{"type":24,"value":751},{"type":24,"value":836},": Then, added the node name, and now Slurmd is running on all nodes! üéâ",{"type":19,"tag":20,"props":838,"children":839},{},[840,844],{"type":19,"tag":147,"props":841,"children":842},{},[843],{"type":24,"value":751},{"type":24,"value":845},": Oh, but Slurmctld won't start because it can't create /var/spool/slurmctld. Of course, it doesn't have permissions... nothing works, help me.",{"type":19,"tag":591,"props":847,"children":849},{"id":848},"the-discussion-reached-the-point-where-we-were-considering-a-full-reset",[850],{"type":24,"value":851},"... The discussion reached the point where we were considering a full reset ...",{"type":19,"tag":853,"props":854,"children":856},"h4",{"id":855},"in-the-meanwhile-saverio-had-news-that-nobody-asked-for",[857],{"type":24,"value":858},"In the meanwhile Saverio had news that nobody asked for",{"type":19,"tag":20,"props":860,"children":861},{},[862,866],{"type":19,"tag":147,"props":863,"children":864},{},[865],{"type":24,"value":779},{"type":24,"value":867},": How cool is the rack?",{"type":19,"tag":32,"props":869,"children":871},{"className":870},[334],[872,874],{"type":24,"value":873},"\n  ",{"type":19,"tag":38,"props":875,"children":877},{"src":876,"alt":8},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732001405/whatsapp1_sqoiwe.jpg",[],{"type":24,"value":879},"   \n",{"type":19,"tag":853,"props":881,"children":883},{"id":882},"in-the-middle-of-desperation-the-only-friendly-answer-to-saverio-was-simones",[884],{"type":24,"value":885},"In the middle of desperation, the only friendly answer to Saverio was Simone's:",{"type":19,"tag":20,"props":887,"children":888},{},[889,894],{"type":19,"tag":147,"props":890,"children":891},{},[892],{"type":24,"value":893},"Simone",{"type":24,"value":895},": Current situation: Ciz and Ernesto desperate between Wi-Fi and Slurm.",{"type":19,"tag":20,"props":897,"children":898},{},[899,903],{"type":19,"tag":147,"props":900,"children":901},{},[902],{"type":24,"value":893},{"type":24,"value":904},": Meanwhile, Saverio in tech support mode:",{"type":19,"tag":32,"props":906,"children":908},{"className":907},[334],[909,911],{"type":24,"value":910},"\n   ",{"type":19,"tag":38,"props":912,"children":914},{"src":913,"alt":8},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732001407/geppetto_muhtxu.jpg",[],{"type":24,"value":916},"  \n",{"type":19,"tag":24,"props":918,"children":921},{"className":919},[920],"centered",[922],{"type":19,"tag":853,"props":923,"children":925},{"id":924},"saverio-officially-crowned-mvp-of-confusion",[926],{"type":24,"value":927},"Saverio, officially crowned MVP of confusion.",{"type":19,"tag":61,"props":929,"children":931},{"id":930},"a-plum-at-the-sc24",[932],{"type":24,"value":933},"A Plum at the SC24",{"type":19,"tag":20,"props":935,"children":936},{},[937,939,944,946,951],{"type":24,"value":938},"This week Lorenzo attended ",{"type":19,"tag":147,"props":940,"children":941},{},[942],{"type":24,"value":943},"SC24",{"type":24,"value":945},", the world's biggest HPC conference! (what a lucky plum he is...)\nIt has been a tremendous experience and... ",{"type":19,"tag":147,"props":947,"children":948},{},[949],{"type":24,"value":950},"OH WAIT",{"type":24,"value":952},", cannot disclose it now, he will write about it!",{"type":19,"tag":20,"props":954,"children":955},{},[956],{"type":24,"value":957},"So, if you want to know what SC24 was about, stay tuned guys",{"type":19,"tag":32,"props":959,"children":960},{},[961,962,965,966],{"type":24,"value":36},{"type":19,"tag":38,"props":963,"children":964},{"src":362,"alt":8},[],{"type":24,"value":36},{"type":19,"tag":43,"props":967,"children":968},{},[969],{"type":24,"value":970},"Lorenzo at the International Conference for High Performance Computing, Networking, Storage, and Analysis",{"type":19,"tag":103,"props":972,"children":974},{":authors":973},"[{\"name\": \"Alessio Olivieri\", \"github_nickname\": \"Alessio-Olivieri\"}]",[],{"title":8,"searchDepth":108,"depth":108,"links":976},[977,980,984,991,992],{"id":367,"depth":108,"text":370,"children":978},[979],{"id":446,"depth":111,"text":449},{"id":528,"depth":108,"text":531,"children":981},[982,983],{"id":572,"depth":111,"text":575},{"id":599,"depth":111,"text":602},{"id":610,"depth":108,"text":613,"children":985},[986,987,988,989,990],{"id":616,"depth":111,"text":619},{"id":627,"depth":111,"text":630},{"id":670,"depth":111,"text":673},{"id":681,"depth":111,"text":684},{"id":725,"depth":111,"text":728},{"id":736,"depth":108,"text":739},{"id":930,"depth":108,"text":933},"content:blog:weekly_update_22-11.md","blog/weekly_update_22-11.md","blog/weekly_update_22-11",{"_path":997,"_dir":6,"_draft":7,"_partial":7,"_locale":8,"title":998,"description":999,"author":1000,"gh_nickname":1001,"image":1002,"date":1003,"body":1004,"_type":114,"_id":1311,"_source":116,"_file":1312,"_stem":1313,"_extension":119},"/blog/a_scalable_raspberry_pi_cluster","A scalable Raspberry Pi cluster","The cluster consists of eight Raspberry Pi 5 nodes: Each node is a compute node with 4GB of RAM and a quad-core ARM processor. Just one special node, with a special role, with a special personality, is a Raspberry Pi 5 with 8GB of RAM and a NVMe SSD mounted. This node is the storage node that provides a shared filesystem for the entire cluster and is used for managing other aspects of the cluster. Each node is powered through Power over Ethernet (PoE) to reduce the need for individual power supplies and simplify the cabling structure. All nodes are connected via two PoE","Francesco Fazzari","CiZ01","https://res.cloudinary.com/dllutk9zl/image/upload/v1731434779/img2_cfcjno.jpg","2024-11-11T00:00:00.000Z",{"type":16,"children":1005,"toc":1302},[1006,1012,1017,1023,1028,1051,1056,1062,1107,1120,1132,1170,1175,1190,1208,1214,1246,1258,1264,1274,1280,1298],{"type":19,"tag":61,"props":1007,"children":1009},{"id":1008},"introduction",[1010],{"type":24,"value":1011},"Introduction",{"type":19,"tag":20,"props":1013,"children":1014},{},[1015],{"type":24,"value":1016},"In this article, we present our project: a compact, simple and scalable cluster, composed of a set of Raspberry Pi 5 connected via Power over Ethernet (PoE) switches. The cluster is designed to be affordable and easy to manage, making it an ideal platform for educational purposes and prototyping distributed applications.",{"type":19,"tag":61,"props":1018,"children":1020},{"id":1019},"why-use-raspberry-pi-for-clustering",[1021],{"type":24,"value":1022},"Why use Raspberry Pi for clustering?",{"type":19,"tag":20,"props":1024,"children":1025},{},[1026],{"type":24,"value":1027},"Raspberry Pi boards offer two main advantages for building a cluster:",{"type":19,"tag":377,"props":1029,"children":1030},{},[1031,1041],{"type":19,"tag":381,"props":1032,"children":1033},{},[1034,1039],{"type":19,"tag":147,"props":1035,"children":1036},{},[1037],{"type":24,"value":1038},"Affordability",{"type":24,"value":1040},": Raspberry Pi boards are budget-friendly, for this type of project, making them accessible for educational institutions, hobbyists, and small businesses.",{"type":19,"tag":381,"props":1042,"children":1043},{},[1044,1049],{"type":19,"tag":147,"props":1045,"children":1046},{},[1047],{"type":24,"value":1048},"Scalability",{"type":24,"value":1050},": Raspberry Pi clusters can be easily scaled by adding more nodes, allowing users to expand their computing power as needed or change the cluster configuration to suit different applications.",{"type":19,"tag":20,"props":1052,"children":1053},{},[1054],{"type":24,"value":1055},"Beyond these advantages, using Raspberry Pis in a cluster opens up a lot of interesting possibilities for experimenting with ARM processors. This kind of project is perfect for getting hands-on experience with distributed computing. It‚Äôs a great way to dive into how small hardware can take on real computing tasks, and it lets us play around with ideas for optimizing performance.",{"type":19,"tag":61,"props":1057,"children":1059},{"id":1058},"hardware-setup",[1060],{"type":24,"value":1061},"Hardware Setup",{"type":19,"tag":20,"props":1063,"children":1064},{},[1065,1067,1072,1074,1079,1081,1086,1088,1093,1094,1099,1100,1105],{"type":24,"value":1066},"The cluster consists of ",{"type":19,"tag":147,"props":1068,"children":1069},{},[1070],{"type":24,"value":1071},"eight Raspberry Pi 5 nodes",{"type":24,"value":1073},":\nEach node is a compute node with ",{"type":19,"tag":147,"props":1075,"children":1076},{},[1077],{"type":24,"value":1078},"4GB of RAM",{"type":24,"value":1080}," and a ",{"type":19,"tag":147,"props":1082,"children":1083},{},[1084],{"type":24,"value":1085},"quad-core ARM processor",{"type":24,"value":1087},".\nJust one special node, with a special role, with a special personality, is a ",{"type":19,"tag":147,"props":1089,"children":1090},{},[1091],{"type":24,"value":1092},"Raspberry Pi 5",{"type":24,"value":504},{"type":19,"tag":147,"props":1095,"children":1096},{},[1097],{"type":24,"value":1098},"8GB of RAM",{"type":24,"value":1080},{"type":19,"tag":147,"props":1101,"children":1102},{},[1103],{"type":24,"value":1104},"NVMe SSD",{"type":24,"value":1106}," mounted. This node is the storage node that provides a shared filesystem for the entire cluster and is used for managing other aspects of the cluster.",{"type":19,"tag":32,"props":1108,"children":1109},{},[1110,1111,1114,1115],{"type":24,"value":36},{"type":19,"tag":38,"props":1112,"children":1113},{"src":1002,"alt":1092},[],{"type":24,"value":36},{"type":19,"tag":43,"props":1116,"children":1117},{},[1118],{"type":24,"value":1119},"Our Raspberry Pi 5, it is a plum",{"type":19,"tag":20,"props":1121,"children":1122},{},[1123,1125,1130],{"type":24,"value":1124},"Each node is powered through ",{"type":19,"tag":147,"props":1126,"children":1127},{},[1128],{"type":24,"value":1129},"Power over Ethernet (PoE)",{"type":24,"value":1131}," this approch allow us to:",{"type":19,"tag":377,"props":1133,"children":1134},{},[1135,1158],{"type":19,"tag":381,"props":1136,"children":1137},{},[1138,1143,1145,1150,1151,1156],{"type":19,"tag":147,"props":1139,"children":1140},{},[1141],{"type":24,"value":1142},"Reduce",{"type":24,"value":1144}," the need for ",{"type":19,"tag":147,"props":1146,"children":1147},{},[1148],{"type":24,"value":1149},"individual power supplies",{"type":24,"value":648},{"type":19,"tag":147,"props":1152,"children":1153},{},[1154],{"type":24,"value":1155},"simplify the cabling structure",{"type":24,"value":1157},", this is an important aspect since each compute node requires 30W of power and a power supply that can provide enough power for a set of nodes is very expensive.",{"type":19,"tag":381,"props":1159,"children":1160},{},[1161,1163,1168],{"type":24,"value":1162},"Each node need a network connection, so we can ",{"type":19,"tag":147,"props":1164,"children":1165},{},[1166],{"type":24,"value":1167},"use the same cable for power and network connection",{"type":24,"value":1169},", ez üßé‚Äç‚ôÄÔ∏è.",{"type":19,"tag":20,"props":1171,"children":1172},{},[1173],{"type":24,"value":1174},"However the current topology is a temporary solution, we are working on improve some aspects of the network configuration, but we need money for this üí∏.",{"type":19,"tag":32,"props":1176,"children":1177},{},[1178,1179,1184,1185],{"type":24,"value":36},{"type":19,"tag":38,"props":1180,"children":1183},{"src":1181,"alt":1182},"https://res.cloudinary.com/dllutk9zl/image/upload/v1731434780/img1_ponf4t.jpg","switch",[],{"type":24,"value":36},{"type":19,"tag":43,"props":1186,"children":1187},{},[1188],{"type":24,"value":1189},"One of our powerfull switch ‚ö°",{"type":19,"tag":20,"props":1191,"children":1192},{},[1193,1195,1200,1202,1206],{"type":24,"value":1194},"Last but not least, the cluster is managed by a very strong ",{"type":19,"tag":147,"props":1196,"children":1197},{},[1198],{"type":24,"value":1199},"Raspberry Pi 3B",{"type":24,"value":1201}," acting as the master and login node. This node is responsible for coordinating tasks, managing the cluster and interacting with the compute nodes. For this kind of usage we have chosen a ",{"type":19,"tag":147,"props":1203,"children":1204},{},[1205],{"type":24,"value":1199},{"type":24,"value":1207}," because it should be enough for this kind of tasks.",{"type":19,"tag":61,"props":1209,"children":1211},{"id":1210},"software-setup",[1212],{"type":24,"value":1213},"Software setup",{"type":19,"tag":20,"props":1215,"children":1216},{},[1217,1219,1224,1226,1231,1233,1237,1239,1244],{"type":24,"value":1218},"Each node run ",{"type":19,"tag":147,"props":1220,"children":1221},{},[1222],{"type":24,"value":1223},"Raspberry Pi OS Lite 64 bits",{"type":24,"value":1225}," , with ",{"type":19,"tag":147,"props":1227,"children":1228},{},[1229],{"type":24,"value":1230},"OpenMPI",{"type":24,"value":1232}," for parallel computing tasks, currently no containerization technology is used, any tasks run in a bare metal environment.",{"type":19,"tag":1234,"props":1235,"children":1236},"br",{},[],{"type":24,"value":1238},"\nAll this hardware need someone to manage them, we choose ",{"type":19,"tag":147,"props":1240,"children":1241},{},[1242],{"type":24,"value":1243},"SLURM",{"type":24,"value":1245}," that is a free and open-source job scheduler, that can be used to manage and schedule the tasks on the cluster. It is a very powerful tool that allows us to manage the resources of the cluster in a very simple way using configuration files, however this is not the place where we can explain how we have configured it and other software that we use in the cluster, maybe in the future we will write an article about it.",{"type":19,"tag":20,"props":1247,"children":1248},{},[1249,1251,1256],{"type":24,"value":1250},"An important aspect of the software setup is the support of th ",{"type":19,"tag":147,"props":1252,"children":1253},{},[1254],{"type":24,"value":1255},"Ansible configuration management tool",{"type":24,"value":1257},", that allows us to manage the configuration of the cluster in a very simple way, we can install software, update the system, and manage the configuration of the cluster with just a command and propagate the changes to all the nodes in the cluster. This is simple to use but it is a pain to configure, however it is worth it üí™.",{"type":19,"tag":61,"props":1259,"children":1261},{"id":1260},"conclusion",[1262],{"type":24,"value":1263},"Conclusion",{"type":19,"tag":20,"props":1265,"children":1266},{},[1267,1269,1272],{"type":24,"value":1268},"Our Raspberry Pi cluster is a flexible, powerful solution that shows how versatile Raspberry Pi boards can be for distributed computing tasks.",{"type":19,"tag":1234,"props":1270,"children":1271},{},[],{"type":24,"value":1273},"\nWhile it‚Äôs not a substitute for large-scale server clusters, it‚Äôs a valuable platform for learning, prototyping, and testing distributed applications.",{"type":19,"tag":49,"props":1275,"children":1277},{"id":1276},"future-works",[1278],{"type":24,"value":1279},"Future Works",{"type":19,"tag":20,"props":1281,"children":1282},{},[1283,1285,1290,1291,1296],{"type":24,"value":1284},"We‚Äôre planning to add new nodes to the cluster (but of course, there are never enough ports on switches üò≠). We‚Äôre also considering adding new hardware to boost node computation, like ",{"type":19,"tag":147,"props":1286,"children":1287},{},[1288],{"type":24,"value":1289},"GPUs",{"type":24,"value":436},{"type":19,"tag":147,"props":1292,"children":1293},{},[1294],{"type":24,"value":1295},"TPUs",{"type":24,"value":1297},", and other accelerators. These upgrades would let us take on more complex tasks and experiment with hardware-accelerated processing, pushing our Pi cluster‚Äôs capabilities even further! üöÄ.",{"type":19,"tag":103,"props":1299,"children":1301},{":authors":1300},"[{\"name\":\"Francesco Fazzari\",\"github_nickname\":\"CiZ01\"}]",[],{"title":8,"searchDepth":108,"depth":108,"links":1303},[1304,1305,1306,1307,1308],{"id":1008,"depth":108,"text":1011},{"id":1019,"depth":108,"text":1022},{"id":1058,"depth":108,"text":1061},{"id":1210,"depth":108,"text":1213},{"id":1260,"depth":108,"text":1263,"children":1309},[1310],{"id":1276,"depth":111,"text":1279},"content:blog:a_scalable_raspberry_pi_cluster.md","blog/a_scalable_raspberry_pi_cluster.md","blog/a_scalable_raspberry_pi_cluster",1734615960114]
[{"data":1,"prerenderedAt":667},["ShallowReactive",2],{"content-query-LLMOD9jdQ5":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"title":8,"description":9,"author":10,"gh_nickname":11,"date":12,"image":13,"body":14,"_type":661,"_id":662,"_source":663,"_file":664,"_stem":665,"_extension":666},"/blog/weekly_update_22-11","blog",false,"","Weekly Update 22-11","The week began with the cluster almost in a ready state, but issues emerged during testing with MPI and SLURM. Specifically: SLURM (srun) Only ran in singleton mode without errors but failed to scale. MPI (mpirun) Crashed outright, returning an error: \"PSEC: munge failed to create credential: Socket communication error.\"","Alessio Olivieri","Alessio-Olivieri","2024-11-22T00:00:00.000Z","https://res.cloudinary.com/dllutk9zl/image/upload/v1732270953/Plum_at_SC24_eozc8d.jpg",{"type":15,"children":16,"toc":641},"root",[17,26,32,74,101,108,120,125,141,146,184,190,209,228,234,243,248,255,261,266,272,278,283,289,328,334,339,345,350,383,389,394,400,591,597,616,621,636],{"type":18,"tag":19,"props":20,"children":22},"element","h2",{"id":21},"cluster-issues-with-mpi-and-slurm",[23],{"type":24,"value":25},"text","Cluster Issues with MPI and SLURM",{"type":18,"tag":27,"props":28,"children":29},"p",{},[30],{"type":24,"value":31},"The week began with the cluster almost in a ready state, but issues emerged during testing with MPI and SLURM. Specifically:",{"type":18,"tag":33,"props":34,"children":35},"ul",{},[36,57],{"type":18,"tag":37,"props":38,"children":39},"li",{},[40,55],{"type":18,"tag":41,"props":42,"children":43},"strong",{},[44,46,53],{"type":24,"value":45},"SLURM (",{"type":18,"tag":47,"props":48,"children":50},"code",{"className":49},[],[51],{"type":24,"value":52},"srun",{"type":24,"value":54},")",{"type":24,"value":56},": Only ran in singleton mode without errors but failed to scale.",{"type":18,"tag":37,"props":58,"children":59},{},[60,72],{"type":18,"tag":41,"props":61,"children":62},{},[63,65,71],{"type":24,"value":64},"MPI (",{"type":18,"tag":47,"props":66,"children":68},{"className":67},[],[69],{"type":24,"value":70},"mpirun",{"type":24,"value":54},{"type":24,"value":73},": Crashed outright, returning an error: \"PSEC: munge failed to create credential: Socket communication error.\"",{"type":18,"tag":27,"props":75,"children":76},{},[77,79,84,86,92,94,99],{"type":24,"value":78},"The issue was ",{"type":18,"tag":41,"props":80,"children":81},{},[82],{"type":24,"value":83},"Munge",{"type":24,"value":85},", a tool SLURM uses for authentication across nodes. Although all nodes had it installed and shared the same ",{"type":18,"tag":47,"props":87,"children":89},{"className":88},[],[90],{"type":24,"value":91},"munge.key",{"type":24,"value":93},", ",{"type":18,"tag":47,"props":95,"children":97},{"className":96},[],[98],{"type":24,"value":70},{"type":24,"value":100}," continued to fail.",{"type":18,"tag":102,"props":103,"children":105},"h3",{"id":104},"solution-attempts-and-breakthrough",[106],{"type":24,"value":107},"Solution Attempts and Breakthrough",{"type":18,"tag":27,"props":109,"children":110},{},[111,113,118],{"type":24,"value":112},"After trying several fixes, we found a relevant article by ",{"type":18,"tag":41,"props":114,"children":115},{},[116],{"type":24,"value":117},"Hossein Ghorbanfekr",{"type":24,"value":119}," on Medium, which detailed a similar setup using Raspberry Pi 4 with a Pi 3 as master: he compiled SLURM, and MPI from scratch and his setup was working, however the same authentication issue persisted.",{"type":18,"tag":27,"props":121,"children":122},{},[123],{"type":24,"value":124},"Later, a deeper research persisted by Ernesto revealed an Intel cluster userâ€™s solution:",{"type":18,"tag":33,"props":126,"children":127},{},[128],{"type":18,"tag":37,"props":129,"children":130},{},[131,133,139],{"type":24,"value":132},"By setting ",{"type":18,"tag":47,"props":134,"children":136},{"className":135},[],[137],{"type":24,"value":138},"PMIX_MCA_psec0=native",{"type":24,"value":140},", MPI bypassed Munge and used its default authentication. This change allowed MPI to communicate properly across nodes without the Munge authentication layer.",{"type":18,"tag":27,"props":142,"children":143},{},[144],{"type":24,"value":145},"Testing this:",{"type":18,"tag":33,"props":147,"children":148},{},[149,171],{"type":18,"tag":37,"props":150,"children":151},{},[152,161,163,169],{"type":18,"tag":41,"props":153,"children":154},{},[155],{"type":18,"tag":47,"props":156,"children":158},{"className":157},[],[159],{"type":24,"value":160},"PMIX_MCA_psec0=munge",{"type":24,"value":162}," with ",{"type":18,"tag":47,"props":164,"children":166},{"className":165},[],[167],{"type":24,"value":168},"srun -n 16 hostname",{"type":24,"value":170}," worked.",{"type":18,"tag":37,"props":172,"children":173},{},[174,182],{"type":18,"tag":41,"props":175,"children":176},{},[177],{"type":18,"tag":47,"props":178,"children":180},{"className":179},[],[181],{"type":24,"value":70},{"type":24,"value":183}," still faced issues, which we plan to address when we have more time, as the current priority is communication stability.",{"type":18,"tag":19,"props":185,"children":187},{"id":186},"hardware-upgrade",[188],{"type":24,"value":189},"Hardware Upgrade",{"type":18,"tag":27,"props":191,"children":192},{},[193,195,200,202,207],{"type":24,"value":194},"We decided to include the previous master ",{"type":18,"tag":41,"props":196,"children":197},{},[198],{"type":24,"value":199},"Ciz0",{"type":24,"value":201}," (The only node with 8GB of RAM) in the computational nodes and passed the role of the master to ",{"type":18,"tag":41,"props":203,"children":204},{},[205],{"type":24,"value":206},"Andrea",{"type":24,"value":208},", a Raspberry Pi 3b with 1 GB of RAM, enhancing the cluster specs:",{"type":18,"tag":33,"props":210,"children":211},{},[212,220],{"type":18,"tag":37,"props":213,"children":214},{},[215],{"type":18,"tag":41,"props":216,"children":217},{},[218],{"type":24,"value":219},"28GB -> 36 GB of RAM",{"type":18,"tag":37,"props":221,"children":222},{},[223],{"type":18,"tag":41,"props":224,"children":225},{},[226],{"type":24,"value":227},"28->32 cores",{"type":18,"tag":102,"props":229,"children":231},{"id":230},"potential-problems-of-this-approach",[232],{"type":24,"value":233},"Potential Problems of this approach",{"type":18,"tag":27,"props":235,"children":236},{},[237,241],{"type":18,"tag":41,"props":238,"children":239},{},[240],{"type":24,"value":199},{"type":24,"value":242}," still handles the filesystem... This might be a potential bottleneck when the multiple users try to use the server at the same time since it has more tasks to do.",{"type":18,"tag":27,"props":244,"children":245},{},[246],{"type":24,"value":247},"The problem will be solved when the filesystem will be handled by the master, which will happen when we get more raspberries",{"type":18,"tag":249,"props":250,"children":252},"h5",{"id":251},"saverio-is-now-satisfied-that-his-previously-underutilized-hardware-was-put-to-work",[253],{"type":24,"value":254},"Saverio is now satisfied that his previously underutilized hardware was put to work!",{"type":18,"tag":102,"props":256,"children":258},{"id":257},"next-steps",[259],{"type":24,"value":260},"Next Steps",{"type":18,"tag":27,"props":262,"children":263},{},[264],{"type":24,"value":265},"Using munge for the authentication will be scheduled for later, as we prioritize cluster stability for the presentation of the 13/11/24 (which has been rescheduled for the 20/11/24)",{"type":18,"tag":19,"props":267,"children":269},{"id":268},"plum-juice-cluster-presentation-in-the-multicore-class",[270],{"type":24,"value":271},"Plum juice cluster presentation in the multicore class",{"type":18,"tag":102,"props":273,"children":275},{"id":274},"make-the-world-know-about-us",[276],{"type":24,"value":277},"Make the world know about us.",{"type":18,"tag":27,"props":279,"children":280},{},[281],{"type":24,"value":282},"Professor De Sensi gave us 15 minutes of it's multicore classto present our cluster to the students. This is a big opportunity to expand the plum juice team and to make the world know about us!",{"type":18,"tag":102,"props":284,"children":286},{"id":285},"whats-the-multicore-course-about",[287],{"type":24,"value":288},"What's the multicore course about?",{"type":18,"tag":27,"props":290,"children":291},{},[292,294,300,301,306,308,313,315,320,321,326],{"type":24,"value":293},"The multicore course has been tought to give a deep understanding and practical experience about parallel programming. This is done by proposing the students homeworks where they have to implement classic parallelizable problems like ",{"type":18,"tag":295,"props":296,"children":297},"em",{},[298],{"type":24,"value":299},"matrix multiplication",{"type":24,"value":93},{"type":18,"tag":295,"props":302,"children":303},{},[304],{"type":24,"value":305},"histograms computation",{"type":24,"value":307}," and ",{"type":18,"tag":295,"props":309,"children":310},{},[311],{"type":24,"value":312},"integral approximation",{"type":24,"value":314},". The taught libraries are: ",{"type":18,"tag":295,"props":316,"children":317},{},[318],{"type":24,"value":319},"MPI, OpenMP, Pthreads",{"type":24,"value":307},{"type":18,"tag":295,"props":322,"children":323},{},[324],{"type":24,"value":325},"Cuda",{"type":24,"value":327},".",{"type":18,"tag":102,"props":329,"children":331},{"id":330},"what-do-we-offer",[332],{"type":24,"value":333},"What do we offer?",{"type":18,"tag":27,"props":335,"children":336},{},[337],{"type":24,"value":338},"The Plum juice team offers to give students the possibility to easily test their applications on a truly multi node system, effectively simulating more expensive clusters like Leonardo.",{"type":18,"tag":102,"props":340,"children":342},{"id":341},"our-expectations",[343],{"type":24,"value":344},"Our expectations.",{"type":18,"tag":27,"props":346,"children":347},{},[348],{"type":24,"value":349},"Every plum has their own expectactions from this presentation:",{"type":18,"tag":33,"props":351,"children":352},{},[353,363,373],{"type":18,"tag":37,"props":354,"children":355},{},[356,361],{"type":18,"tag":41,"props":357,"children":358},{},[359],{"type":24,"value":360},"Ciz:",{"type":24,"value":362}," We're dumb",{"type":18,"tag":37,"props":364,"children":365},{},[366,371],{"type":18,"tag":41,"props":367,"children":368},{},[369],{"type":24,"value":370},"Saverio:",{"type":24,"value":372}," I expect money",{"type":18,"tag":37,"props":374,"children":375},{},[376,381],{"type":18,"tag":41,"props":377,"children":378},{},[379],{"type":24,"value":380},"Lachi:",{"type":24,"value":382}," ehhh booh... nobody will be interested",{"type":18,"tag":102,"props":384,"children":386},{"id":385},"where-and-when-can-you-find-us",[387],{"type":24,"value":388},"Where and when can you find us:",{"type":18,"tag":27,"props":390,"children":391},{},[392],{"type":24,"value":393},"Aula A1, Via del Castro Laurenziano at 14:00.",{"type":18,"tag":19,"props":395,"children":397},{"id":396},"behind-the-scenes-when-nothing-was-still-working",[398],{"type":24,"value":399},"Behind the scenes, when nothing was still working",{"type":18,"tag":401,"props":402,"children":403},"blockquote",{},[404,414,423,432,442,451,460,469,479,488,497,506,512,519,528,541,543,549,559,568,578,580],{"type":18,"tag":27,"props":405,"children":406},{},[407,412],{"type":18,"tag":41,"props":408,"children":409},{},[410],{"type":24,"value":411},"Ciz",{"type":24,"value":413},": Ok, now Slurm is starting!",{"type":18,"tag":27,"props":415,"children":416},{},[417,421],{"type":18,"tag":41,"props":418,"children":419},{},[420],{"type":24,"value":411},{"type":24,"value":422},": Oh no, just kidding... it can't find the node name. Perfect, we're off to a great start.",{"type":18,"tag":27,"props":424,"children":425},{},[426,430],{"type":18,"tag":41,"props":427,"children":428},{},[429],{"type":24,"value":411},{"type":24,"value":431},": Guys, the configuration file is full of errors... honestly, it's embarrassing.",{"type":18,"tag":27,"props":433,"children":434},{},[435,440],{"type":18,"tag":41,"props":436,"children":437},{},[438],{"type":24,"value":439},"Saverio",{"type":24,"value":441},": Umm... maybe because you're running it from the master? Just a thought.",{"type":18,"tag":27,"props":443,"children":444},{},[445,449],{"type":18,"tag":41,"props":446,"children":447},{},[448],{"type":24,"value":411},{"type":24,"value":450},": Why doesn't poor ciz0 have Slurm installed? This is discrimination!",{"type":18,"tag":27,"props":452,"children":453},{},[454,458],{"type":18,"tag":41,"props":455,"children":456},{},[457],{"type":24,"value":411},{"type":24,"value":459},": Fine, I just need to add it to the playbook, right?",{"type":18,"tag":27,"props":461,"children":462},{},[463,467],{"type":18,"tag":41,"props":464,"children":465},{},[466],{"type":24,"value":411},{"type":24,"value":468},": Wait, so it's not installed at all. Great.",{"type":18,"tag":27,"props":470,"children":471},{},[472,477],{"type":18,"tag":41,"props":473,"children":474},{},[475],{"type":24,"value":476},"Ernesto",{"type":24,"value":478},": Actually, if there's no Munge, Slurm won't even acknowledge you. It's like an honor code.",{"type":18,"tag":27,"props":480,"children":481},{},[482,486],{"type":18,"tag":41,"props":483,"children":484},{},[485],{"type":24,"value":411},{"type":24,"value":487},": Ok, summary: changed the master password, removed TaskAffinity from the config because it was throwing errors anyway. Don't ask me why it's in the docs, but it doesn't work.",{"type":18,"tag":27,"props":489,"children":490},{},[491,495],{"type":18,"tag":41,"props":492,"children":493},{},[494],{"type":24,"value":411},{"type":24,"value":496},": Then, added the node name, and now Slurmd is running on all nodes! ðŸŽ‰",{"type":18,"tag":27,"props":498,"children":499},{},[500,504],{"type":18,"tag":41,"props":501,"children":502},{},[503],{"type":24,"value":411},{"type":24,"value":505},": Oh, but Slurmctld won't start because it can't create /var/spool/slurmctld. Of course, it doesn't have permissions... nothing works, help me.",{"type":18,"tag":249,"props":507,"children":509},{"id":508},"the-discussion-reached-the-point-where-we-were-considering-a-full-reset",[510],{"type":24,"value":511},"... The discussion reached the point where we were considering a full reset ...",{"type":18,"tag":513,"props":514,"children":516},"h4",{"id":515},"in-the-meanwhile-saverio-had-news-that-nobody-asked-for",[517],{"type":24,"value":518},"In the meanwhile Saverio had news that nobody asked for",{"type":18,"tag":27,"props":520,"children":521},{},[522,526],{"type":18,"tag":41,"props":523,"children":524},{},[525],{"type":24,"value":439},{"type":24,"value":527},": How cool is the rack?",{"type":18,"tag":529,"props":530,"children":533},"figure",{"className":531},[532],"not-centerd",[534,536],{"type":24,"value":535},"\n  ",{"type":18,"tag":537,"props":538,"children":540},"img",{"src":539,"alt":7},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732001405/whatsapp1_sqoiwe.jpg",[],{"type":24,"value":542},"   \n",{"type":18,"tag":513,"props":544,"children":546},{"id":545},"in-the-middle-of-desperation-the-only-friendly-answer-to-saverio-was-simones",[547],{"type":24,"value":548},"In the middle of desperation, the only friendly answer to Saverio was Simone's:",{"type":18,"tag":27,"props":550,"children":551},{},[552,557],{"type":18,"tag":41,"props":553,"children":554},{},[555],{"type":24,"value":556},"Simone",{"type":24,"value":558},": Current situation: Ciz and Ernesto desperate between Wi-Fi and Slurm.",{"type":18,"tag":27,"props":560,"children":561},{},[562,566],{"type":18,"tag":41,"props":563,"children":564},{},[565],{"type":24,"value":556},{"type":24,"value":567},": Meanwhile, Saverio in tech support mode:",{"type":18,"tag":529,"props":569,"children":571},{"className":570},[532],[572,574],{"type":24,"value":573},"\n   ",{"type":18,"tag":537,"props":575,"children":577},{"src":576,"alt":7},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732001407/geppetto_muhtxu.jpg",[],{"type":24,"value":579},"  \n",{"type":18,"tag":24,"props":581,"children":584},{"className":582},[583],"centered",[585],{"type":18,"tag":513,"props":586,"children":588},{"id":587},"saverio-officially-crowned-mvp-of-confusion",[589],{"type":24,"value":590},"Saverio, officially crowned MVP of confusion.",{"type":18,"tag":19,"props":592,"children":594},{"id":593},"a-plum-at-the-sc24",[595],{"type":24,"value":596},"A Plum at the SC24",{"type":18,"tag":27,"props":598,"children":599},{},[600,602,607,609,614],{"type":24,"value":601},"This week Lorenzo attended ",{"type":18,"tag":41,"props":603,"children":604},{},[605],{"type":24,"value":606},"SC24",{"type":24,"value":608},", the world's biggest HPC conference! (what a lucky plum he is...)\nIt has been a tremendous experience and... ",{"type":18,"tag":41,"props":610,"children":611},{},[612],{"type":24,"value":613},"OH WAIT",{"type":24,"value":615},", cannot disclose it now, he will write about it!",{"type":18,"tag":27,"props":617,"children":618},{},[619],{"type":24,"value":620},"So, if you want to know what SC24 was about, stay tuned guys",{"type":18,"tag":529,"props":622,"children":623},{},[624,626,629,630],{"type":24,"value":625},"\n    ",{"type":18,"tag":537,"props":627,"children":628},{"src":13,"alt":7},[],{"type":24,"value":625},{"type":18,"tag":631,"props":632,"children":633},"figcaption",{},[634],{"type":24,"value":635},"Lorenzo at the International Conference for High Performance Computing, Networking, Storage, and Analysis",{"type":18,"tag":637,"props":638,"children":640},"credits",{":authors":639},"[{\"name\": \"Alessio Olivieri\", \"github_nickname\": \"Alessio-Olivieri\"}]",[],{"title":7,"searchDepth":642,"depth":642,"links":643},2,[644,648,652,659,660],{"id":21,"depth":642,"text":25,"children":645},[646],{"id":104,"depth":647,"text":107},3,{"id":186,"depth":642,"text":189,"children":649},[650,651],{"id":230,"depth":647,"text":233},{"id":257,"depth":647,"text":260},{"id":268,"depth":642,"text":271,"children":653},[654,655,656,657,658],{"id":274,"depth":647,"text":277},{"id":285,"depth":647,"text":288},{"id":330,"depth":647,"text":333},{"id":341,"depth":647,"text":344},{"id":385,"depth":647,"text":388},{"id":396,"depth":642,"text":399},{"id":593,"depth":642,"text":596},"markdown","content:blog:weekly_update_22-11.md","content","blog/weekly_update_22-11.md","blog/weekly_update_22-11","md",1740182646073]
[{"data":1,"prerenderedAt":669},["ShallowReactive",2],{"content-query-LLMOD9jdQ5":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"title":8,"description":9,"author":10,"gh_nickname":11,"SLURM (srun) Only ran in singleton mode without errors but failed to scale":12,"date":14,"image":15,"body":16,"_type":663,"_id":664,"_source":665,"_file":666,"_stem":667,"_extension":668},"/blog/weekly_update_22-11","blog",false,"","Weekly Update 22-11","The week began with the cluster almost in a ready state, but issues emerged during testing with MPI and SLURM. Specifically","Alessio Olivieri","Alessio-Olivieri",{" MPI (mpirun) Crashed outright, returning an error":13},"PSEC: munge failed to create credential: Socket communication error.","2024-11-22","https://res.cloudinary.com/dllutk9zl/image/upload/v1732270953/Plum_at_SC24_eozc8d.jpg",{"type":17,"children":18,"toc":643},"root",[19,28,34,76,103,110,122,127,143,148,186,192,211,230,236,245,250,257,263,268,274,280,285,291,330,336,341,347,352,385,391,396,402,593,599,618,623,638],{"type":20,"tag":21,"props":22,"children":24},"element","h2",{"id":23},"cluster-issues-with-mpi-and-slurm",[25],{"type":26,"value":27},"text","Cluster Issues with MPI and SLURM",{"type":20,"tag":29,"props":30,"children":31},"p",{},[32],{"type":26,"value":33},"The week began with the cluster almost in a ready state, but issues emerged during testing with MPI and SLURM. Specifically:",{"type":20,"tag":35,"props":36,"children":37},"ul",{},[38,59],{"type":20,"tag":39,"props":40,"children":41},"li",{},[42,57],{"type":20,"tag":43,"props":44,"children":45},"strong",{},[46,48,55],{"type":26,"value":47},"SLURM (",{"type":20,"tag":49,"props":50,"children":52},"code",{"className":51},[],[53],{"type":26,"value":54},"srun",{"type":26,"value":56},")",{"type":26,"value":58},": Only ran in singleton mode without errors but failed to scale.",{"type":20,"tag":39,"props":60,"children":61},{},[62,74],{"type":20,"tag":43,"props":63,"children":64},{},[65,67,73],{"type":26,"value":66},"MPI (",{"type":20,"tag":49,"props":68,"children":70},{"className":69},[],[71],{"type":26,"value":72},"mpirun",{"type":26,"value":56},{"type":26,"value":75},": Crashed outright, returning an error: \"PSEC: munge failed to create credential: Socket communication error.\"",{"type":20,"tag":29,"props":77,"children":78},{},[79,81,86,88,94,96,101],{"type":26,"value":80},"The issue was ",{"type":20,"tag":43,"props":82,"children":83},{},[84],{"type":26,"value":85},"Munge",{"type":26,"value":87},", a tool SLURM uses for authentication across nodes. Although all nodes had it installed and shared the same ",{"type":20,"tag":49,"props":89,"children":91},{"className":90},[],[92],{"type":26,"value":93},"munge.key",{"type":26,"value":95},", ",{"type":20,"tag":49,"props":97,"children":99},{"className":98},[],[100],{"type":26,"value":72},{"type":26,"value":102}," continued to fail.",{"type":20,"tag":104,"props":105,"children":107},"h3",{"id":106},"solution-attempts-and-breakthrough",[108],{"type":26,"value":109},"Solution Attempts and Breakthrough",{"type":20,"tag":29,"props":111,"children":112},{},[113,115,120],{"type":26,"value":114},"After trying several fixes, we found a relevant article by ",{"type":20,"tag":43,"props":116,"children":117},{},[118],{"type":26,"value":119},"Hossein Ghorbanfekr",{"type":26,"value":121}," on Medium, which detailed a similar setup using Raspberry Pi 4 with a Pi 3 as master: he compiled SLURM, and MPI from scratch and his setup was working, however the same authentication issue persisted.",{"type":20,"tag":29,"props":123,"children":124},{},[125],{"type":26,"value":126},"Later, a deeper research persisted by Ernesto revealed an Intel cluster userâ€™s solution:",{"type":20,"tag":35,"props":128,"children":129},{},[130],{"type":20,"tag":39,"props":131,"children":132},{},[133,135,141],{"type":26,"value":134},"By setting ",{"type":20,"tag":49,"props":136,"children":138},{"className":137},[],[139],{"type":26,"value":140},"PMIX_MCA_psec0=native",{"type":26,"value":142},", MPI bypassed Munge and used its default authentication. This change allowed MPI to communicate properly across nodes without the Munge authentication layer.",{"type":20,"tag":29,"props":144,"children":145},{},[146],{"type":26,"value":147},"Testing this:",{"type":20,"tag":35,"props":149,"children":150},{},[151,173],{"type":20,"tag":39,"props":152,"children":153},{},[154,163,165,171],{"type":20,"tag":43,"props":155,"children":156},{},[157],{"type":20,"tag":49,"props":158,"children":160},{"className":159},[],[161],{"type":26,"value":162},"PMIX_MCA_psec0=munge",{"type":26,"value":164}," with ",{"type":20,"tag":49,"props":166,"children":168},{"className":167},[],[169],{"type":26,"value":170},"srun -n 16 hostname",{"type":26,"value":172}," worked.",{"type":20,"tag":39,"props":174,"children":175},{},[176,184],{"type":20,"tag":43,"props":177,"children":178},{},[179],{"type":20,"tag":49,"props":180,"children":182},{"className":181},[],[183],{"type":26,"value":72},{"type":26,"value":185}," still faced issues, which we plan to address when we have more time, as the current priority is communication stability.",{"type":20,"tag":21,"props":187,"children":189},{"id":188},"hardware-upgrade",[190],{"type":26,"value":191},"Hardware Upgrade",{"type":20,"tag":29,"props":193,"children":194},{},[195,197,202,204,209],{"type":26,"value":196},"We decided to include the previous master ",{"type":20,"tag":43,"props":198,"children":199},{},[200],{"type":26,"value":201},"Ciz0",{"type":26,"value":203}," (The only node with 8GB of RAM) in the computational nodes and passed the role of the master to ",{"type":20,"tag":43,"props":205,"children":206},{},[207],{"type":26,"value":208},"Andrea",{"type":26,"value":210},", a Raspberry Pi 3b with 1 GB of RAM, enhancing the cluster specs:",{"type":20,"tag":35,"props":212,"children":213},{},[214,222],{"type":20,"tag":39,"props":215,"children":216},{},[217],{"type":20,"tag":43,"props":218,"children":219},{},[220],{"type":26,"value":221},"28GB -> 36 GB of RAM",{"type":20,"tag":39,"props":223,"children":224},{},[225],{"type":20,"tag":43,"props":226,"children":227},{},[228],{"type":26,"value":229},"28->32 cores",{"type":20,"tag":104,"props":231,"children":233},{"id":232},"potential-problems-of-this-approach",[234],{"type":26,"value":235},"Potential Problems of this approach",{"type":20,"tag":29,"props":237,"children":238},{},[239,243],{"type":20,"tag":43,"props":240,"children":241},{},[242],{"type":26,"value":201},{"type":26,"value":244}," still handles the filesystem... This might be a potential bottleneck when the multiple users try to use the server at the same time since it has more tasks to do.",{"type":20,"tag":29,"props":246,"children":247},{},[248],{"type":26,"value":249},"The problem will be solved when the filesystem will be handled by the master, which will happen when we get more raspberries",{"type":20,"tag":251,"props":252,"children":254},"h5",{"id":253},"saverio-is-now-satisfied-that-his-previously-underutilized-hardware-was-put-to-work",[255],{"type":26,"value":256},"Saverio is now satisfied that his previously underutilized hardware was put to work!",{"type":20,"tag":104,"props":258,"children":260},{"id":259},"next-steps",[261],{"type":26,"value":262},"Next Steps",{"type":20,"tag":29,"props":264,"children":265},{},[266],{"type":26,"value":267},"Using munge for the authentication will be scheduled for later, as we prioritize cluster stability for the presentation of the 13/11/24 (which has been rescheduled for the 20/11/24)",{"type":20,"tag":21,"props":269,"children":271},{"id":270},"plum-juice-cluster-presentation-in-the-multicore-class",[272],{"type":26,"value":273},"Plum juice cluster presentation in the multicore class",{"type":20,"tag":104,"props":275,"children":277},{"id":276},"make-the-world-know-about-us",[278],{"type":26,"value":279},"Make the world know about us.",{"type":20,"tag":29,"props":281,"children":282},{},[283],{"type":26,"value":284},"Professor De Sensi gave us 15 minutes of it's multicore classto present our cluster to the students. This is a big opportunity to expand the plum juice team and to make the world know about us!",{"type":20,"tag":104,"props":286,"children":288},{"id":287},"whats-the-multicore-course-about",[289],{"type":26,"value":290},"What's the multicore course about?",{"type":20,"tag":29,"props":292,"children":293},{},[294,296,302,303,308,310,315,317,322,323,328],{"type":26,"value":295},"The multicore course has been tought to give a deep understanding and practical experience about parallel programming. This is done by proposing the students homeworks where they have to implement classic parallelizable problems like ",{"type":20,"tag":297,"props":298,"children":299},"em",{},[300],{"type":26,"value":301},"matrix multiplication",{"type":26,"value":95},{"type":20,"tag":297,"props":304,"children":305},{},[306],{"type":26,"value":307},"histograms computation",{"type":26,"value":309}," and ",{"type":20,"tag":297,"props":311,"children":312},{},[313],{"type":26,"value":314},"integral approximation",{"type":26,"value":316},". The taught libraries are: ",{"type":20,"tag":297,"props":318,"children":319},{},[320],{"type":26,"value":321},"MPI, OpenMP, Pthreads",{"type":26,"value":309},{"type":20,"tag":297,"props":324,"children":325},{},[326],{"type":26,"value":327},"Cuda",{"type":26,"value":329},".",{"type":20,"tag":104,"props":331,"children":333},{"id":332},"what-do-we-offer",[334],{"type":26,"value":335},"What do we offer?",{"type":20,"tag":29,"props":337,"children":338},{},[339],{"type":26,"value":340},"The Plum juice team offers to give students the possibility to easily test their applications on a truly multi node system, effectively simulating more expensive clusters like Leonardo.",{"type":20,"tag":104,"props":342,"children":344},{"id":343},"our-expectations",[345],{"type":26,"value":346},"Our expectations.",{"type":20,"tag":29,"props":348,"children":349},{},[350],{"type":26,"value":351},"Every plum has their own expectactions from this presentation:",{"type":20,"tag":35,"props":353,"children":354},{},[355,365,375],{"type":20,"tag":39,"props":356,"children":357},{},[358,363],{"type":20,"tag":43,"props":359,"children":360},{},[361],{"type":26,"value":362},"Ciz:",{"type":26,"value":364}," We're dumb",{"type":20,"tag":39,"props":366,"children":367},{},[368,373],{"type":20,"tag":43,"props":369,"children":370},{},[371],{"type":26,"value":372},"Saverio:",{"type":26,"value":374}," I expect money",{"type":20,"tag":39,"props":376,"children":377},{},[378,383],{"type":20,"tag":43,"props":379,"children":380},{},[381],{"type":26,"value":382},"Lachi:",{"type":26,"value":384}," ehhh booh... nobody will be interested",{"type":20,"tag":104,"props":386,"children":388},{"id":387},"where-and-when-can-you-find-us",[389],{"type":26,"value":390},"Where and when can you find us:",{"type":20,"tag":29,"props":392,"children":393},{},[394],{"type":26,"value":395},"Aula A1, Via del Castro Laurenziano at 14:00.",{"type":20,"tag":21,"props":397,"children":399},{"id":398},"behind-the-scenes-when-nothing-was-still-working",[400],{"type":26,"value":401},"Behind the scenes, when nothing was still working",{"type":20,"tag":403,"props":404,"children":405},"blockquote",{},[406,416,425,434,444,453,462,471,481,490,499,508,514,521,530,543,545,551,561,570,580,582],{"type":20,"tag":29,"props":407,"children":408},{},[409,414],{"type":20,"tag":43,"props":410,"children":411},{},[412],{"type":26,"value":413},"Ciz",{"type":26,"value":415},": Ok, now Slurm is starting!",{"type":20,"tag":29,"props":417,"children":418},{},[419,423],{"type":20,"tag":43,"props":420,"children":421},{},[422],{"type":26,"value":413},{"type":26,"value":424},": Oh no, just kidding... it can't find the node name. Perfect, we're off to a great start.",{"type":20,"tag":29,"props":426,"children":427},{},[428,432],{"type":20,"tag":43,"props":429,"children":430},{},[431],{"type":26,"value":413},{"type":26,"value":433},": Guys, the configuration file is full of errors... honestly, it's embarrassing.",{"type":20,"tag":29,"props":435,"children":436},{},[437,442],{"type":20,"tag":43,"props":438,"children":439},{},[440],{"type":26,"value":441},"Saverio",{"type":26,"value":443},": Umm... maybe because you're running it from the master? Just a thought.",{"type":20,"tag":29,"props":445,"children":446},{},[447,451],{"type":20,"tag":43,"props":448,"children":449},{},[450],{"type":26,"value":413},{"type":26,"value":452},": Why doesn't poor ciz0 have Slurm installed? This is discrimination!",{"type":20,"tag":29,"props":454,"children":455},{},[456,460],{"type":20,"tag":43,"props":457,"children":458},{},[459],{"type":26,"value":413},{"type":26,"value":461},": Fine, I just need to add it to the playbook, right?",{"type":20,"tag":29,"props":463,"children":464},{},[465,469],{"type":20,"tag":43,"props":466,"children":467},{},[468],{"type":26,"value":413},{"type":26,"value":470},": Wait, so it's not installed at all. Great.",{"type":20,"tag":29,"props":472,"children":473},{},[474,479],{"type":20,"tag":43,"props":475,"children":476},{},[477],{"type":26,"value":478},"Ernesto",{"type":26,"value":480},": Actually, if there's no Munge, Slurm won't even acknowledge you. It's like an honor code.",{"type":20,"tag":29,"props":482,"children":483},{},[484,488],{"type":20,"tag":43,"props":485,"children":486},{},[487],{"type":26,"value":413},{"type":26,"value":489},": Ok, summary: changed the master password, removed TaskAffinity from the config because it was throwing errors anyway. Don't ask me why it's in the docs, but it doesn't work.",{"type":20,"tag":29,"props":491,"children":492},{},[493,497],{"type":20,"tag":43,"props":494,"children":495},{},[496],{"type":26,"value":413},{"type":26,"value":498},": Then, added the node name, and now Slurmd is running on all nodes! ðŸŽ‰",{"type":20,"tag":29,"props":500,"children":501},{},[502,506],{"type":20,"tag":43,"props":503,"children":504},{},[505],{"type":26,"value":413},{"type":26,"value":507},": Oh, but Slurmctld won't start because it can't create /var/spool/slurmctld. Of course, it doesn't have permissions... nothing works, help me.",{"type":20,"tag":251,"props":509,"children":511},{"id":510},"the-discussion-reached-the-point-where-we-were-considering-a-full-reset",[512],{"type":26,"value":513},"... The discussion reached the point where we were considering a full reset ...",{"type":20,"tag":515,"props":516,"children":518},"h4",{"id":517},"in-the-meanwhile-saverio-had-news-that-nobody-asked-for",[519],{"type":26,"value":520},"In the meanwhile Saverio had news that nobody asked for",{"type":20,"tag":29,"props":522,"children":523},{},[524,528],{"type":20,"tag":43,"props":525,"children":526},{},[527],{"type":26,"value":441},{"type":26,"value":529},": How cool is the rack?",{"type":20,"tag":531,"props":532,"children":535},"figure",{"className":533},[534],"not-centerd",[536,538],{"type":26,"value":537},"\n  ",{"type":20,"tag":539,"props":540,"children":542},"img",{"src":541,"alt":7},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732001405/whatsapp1_sqoiwe.jpg",[],{"type":26,"value":544},"   \n",{"type":20,"tag":515,"props":546,"children":548},{"id":547},"in-the-middle-of-desperation-the-only-friendly-answer-to-saverio-was-simones",[549],{"type":26,"value":550},"In the middle of desperation, the only friendly answer to Saverio was Simone's:",{"type":20,"tag":29,"props":552,"children":553},{},[554,559],{"type":20,"tag":43,"props":555,"children":556},{},[557],{"type":26,"value":558},"Simone",{"type":26,"value":560},": Current situation: Ciz and Ernesto desperate between Wi-Fi and Slurm.",{"type":20,"tag":29,"props":562,"children":563},{},[564,568],{"type":20,"tag":43,"props":565,"children":566},{},[567],{"type":26,"value":558},{"type":26,"value":569},": Meanwhile, Saverio in tech support mode:",{"type":20,"tag":531,"props":571,"children":573},{"className":572},[534],[574,576],{"type":26,"value":575},"\n   ",{"type":20,"tag":539,"props":577,"children":579},{"src":578,"alt":7},"https://res.cloudinary.com/dllutk9zl/image/upload/v1732001407/geppetto_muhtxu.jpg",[],{"type":26,"value":581},"  \n",{"type":20,"tag":26,"props":583,"children":586},{"className":584},[585],"centered",[587],{"type":20,"tag":515,"props":588,"children":590},{"id":589},"saverio-officially-crowned-mvp-of-confusion",[591],{"type":26,"value":592},"Saverio, officially crowned MVP of confusion.",{"type":20,"tag":21,"props":594,"children":596},{"id":595},"a-plum-at-the-sc24",[597],{"type":26,"value":598},"A Plum at the SC24",{"type":20,"tag":29,"props":600,"children":601},{},[602,604,609,611,616],{"type":26,"value":603},"This week Lorenzo attended ",{"type":20,"tag":43,"props":605,"children":606},{},[607],{"type":26,"value":608},"SC24",{"type":26,"value":610},", the world's biggest HPC conference! (what a lucky plum he is...)\nIt has been a tremendous experience and... ",{"type":20,"tag":43,"props":612,"children":613},{},[614],{"type":26,"value":615},"OH WAIT",{"type":26,"value":617},", cannot disclose it now, he will write about it!",{"type":20,"tag":29,"props":619,"children":620},{},[621],{"type":26,"value":622},"So, if you want to know what SC24 was about, stay tuned guys",{"type":20,"tag":531,"props":624,"children":625},{},[626,628,631,632],{"type":26,"value":627},"\n    ",{"type":20,"tag":539,"props":629,"children":630},{"src":15,"alt":7},[],{"type":26,"value":627},{"type":20,"tag":633,"props":634,"children":635},"figcaption",{},[636],{"type":26,"value":637},"Lorenzo at the International Conference for High Performance Computing, Networking, Storage, and Analysis",{"type":20,"tag":639,"props":640,"children":642},"credits",{":authors":641},"[{\"name\": \"Alessio Olivieri\", \"github_nickname\": \"Alessio-Olivieri\"}]",[],{"title":7,"searchDepth":644,"depth":644,"links":645},2,[646,650,654,661,662],{"id":23,"depth":644,"text":27,"children":647},[648],{"id":106,"depth":649,"text":109},3,{"id":188,"depth":644,"text":191,"children":651},[652,653],{"id":232,"depth":649,"text":235},{"id":259,"depth":649,"text":262},{"id":270,"depth":644,"text":273,"children":655},[656,657,658,659,660],{"id":276,"depth":649,"text":279},{"id":287,"depth":649,"text":290},{"id":332,"depth":649,"text":335},{"id":343,"depth":649,"text":346},{"id":387,"depth":649,"text":390},{"id":398,"depth":644,"text":401},{"id":595,"depth":644,"text":598},"markdown","content:blog:weekly_update_22-11.md","content","blog/weekly_update_22-11.md","blog/weekly_update_22-11","md",1770921053138]